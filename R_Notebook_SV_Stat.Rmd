---
title: "Overview of Statistical Elements and Tests"
author: Samuel Vincent
output: html_notebook
---

# Preface
This R Notebook will contain information on various elements and tests used in statistical analyses. These will include t-tests, Wilcoxon tests, ANOVA, linear regressions and correlation tests, as well as elements such as hypotheses and p-values. In addition, I will be covering when it is appropriate to use each test and the assumptions of each one. Finally, I will be covering four types of data visualization methods: histograms, box plots, heat maps and  pie charts. I believe this will be a valuable asset for future statistical analyses on my end.

# The Primary Statistical Tests
As mentioned before, the primary statistical tests are the t-test, Wilcoxon test, ANOVA, linear regression and correlation tests. These are the tools with which a data analyst will derive meaningful information from raw data.

## T-tests
### Overview
**T-tests** (or Student's T-tests) are used to determine the difference of **two means**, each from a different group. These are generally the first type of statistical test one will learn about, as it is the most frequently-used type. It only relies on a singular numerical variable, as opposed to multiple variables. 

It was initially created by **William S. Gosset**, an English statistician employed at the Guinness Brewery in Dublin. By the 1970s, this test was available in most software statistical packages.^[https://www.statisticshowto.com/probability-and-statistics/t-test/#assump]

### Assumptions
* When using a t-test, we have to assume:
  + The data follows a normal distribution
  + Observations of one group are independent of observations of the other
  + There are equal variances in the data
  
### When to Use It
T-tests should be used in scenarios where there are only two groups to derive means from. These can be two measurements of the same entity, or it can involve two entities that are being measured with unique properties or conditions.

### Hypotheses
* When using a t-test, the null and alternative hypotheses are:
  + Ho: There is not a difference between the two groups' means
  + Ha: There is a significant difference between the two groups' means
  
## Wilcoxon Tests
### Overview
The **Wilcoxon test** (a.k.a. Wilcoxon signed rank test) is similar to the t-test, with one significant difference: it is **nonparametric**. This means that the test doesn't assume that the data follows a distribution.^[https://statisticsbyjim.com/hypothesis-testing/wilcoxon-signed-rank-test/]

This test was created by **Frank Wilcoxon** in 1945, in the same scientific paper that also presented the rank-sum test. It was popularized by American psychologist and statistician Sidney Siegel in 1965.^[https://online.stat.psu.edu/stat415/lesson/20/20.2]
 
### Assumptions
* When performing a Wilcox test, we assume:
    + The data follows no particular distribution
    
### When to Use It
Statisticians will use Wilcox tests when the above assumption is true. In addition to this, this is preferred over t-tests because of increased power through its ability to analyze **ordinal data** (data that is categorized but differences between each category aren't identifiable) and reduce outlier impact.

### Hypotheses
Since there are two types of Wilcox tests, one-sample and paired, there are a pair of null and alternative hypotheses for each one.

* For the one-sample test:
   + Ho: The population median is the same as the benchmark value
   + Ha: The population median is significantly different from the benchmark value
* For the paired test:
    + Ho: The median of the paired differences cancel each other out (=0) in the overall population
    + Ha: The median of the paired differences don't equal zero in the overall population

## ANOVA
### Overview
The **ANOVA** (a.k.a. Analysis of Variance) test is used to see of the means of **three or more groups** for significant differences among them.^[https://researchmethod.net/anova/] This assists statisticians with determining whether differences observed in the groups' means are due to chance or caused by true effects of the property applied to them. This makes it similar to the t-test, only it has the capacity for 3+ groups' means.

This test was devised by **R. A. Fisher**, a British statistician, in 1918. It was developed using the t-test as a reference point, which explains its similarities.^[https://www.britannica.com/topic/variance-analysis-statistics]

### Assumptions
* When utilizing an ANOVA, we assume:
    + The data follows a normal distribution
    + Observations of one group are independent of observations of the other
    + There are equal variances in the data

Note that these assumptions are the same as with a t-test. 

### When to Use It
People typically use ANOVA tests when there are three or more groups of data from which means can be derived. By grouping all of these data together, this consequently reduces the risk of false significance in the results.

### Hypotheses
* The null and alternative hypotheses of an ANOVA test are almost the same as with a t-test, which are:
    + Ho: There is no difference between the means of the 3+ groups of data
    + Ha: There is a significant difference between the means of the 3+ groups of data. More specifically, at least one group of data contains a significantly-different mean from the others
    
## Linear Regression
### Overview
**Linear regression** is a statistical model that details the relationships between at least one **explanatory variable** (any variable that predicts changes in another variable^[https://statisticsbyjim.com/glossary/explanatory-variable/]) and an **outcome variable** (the variable that's being affected by the explanatory variable^[https://statisticsbyjim.com/glossary/response-variable/]). ^[https://statisticsbyjim.com/regression/linear-regression/#google_vignette]

It is one of the earliest types of regression analyses.

### Assumptions
* When conducting a linear regression analysis, we assume:
    + Normal distribution of data
    + A linear formula fits the variables' relationship
    + Constant scattering among residuals
    + Any observations of the data are independent from each other
    
### When to Use It
Linear regression analyses are used when the relationship between variables are desired, as well as when this relationship is thought to be represented by a linear formula, such as y=mx+b. This in turn serves to predict changes in certain variables by changes in others, the basis of clinical research. 

### Hypotheses
* The null and alternative hypotheses of the linear regression analysis are:
    + Ho: The slope of the population equals zero (in the formula y=β₀+β₁+ε
 ). The hypotheses focus on the status of β₁ in this instance^[https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Mostly_Harmless_Statistics_(Webb)/12%3A_Correlation_and_Regression/12.02%3A_Simple_Linear_Regression/12.2.01%3A_Hypothesis_Test_for_Linear_Regression]
    + Ha: The slope of the population doesn't equal zero
    
## Correlation Test
### Overview
The **correlation test** (a.k.a. correlation hypothesis test) is used to determine the strength and direction of the relationship between two variables.^[https://stats.libretexts.org/Courses/Rio_Hondo_College/Math_130%3A_Statistics/11%3A_Correlation/11.03%3A_Correlation_Hypothesis_Test] This statistical test does this through use of the correlation coefficient and sample size. 

### Assumptions
* When using this test, we assume:
    + Normal data distribution
    + A linear relationship between two variables of interest^[https://usq.pressbooks.pub/statisticsforresearchstudents/chapter/correlation-assumptions/]
    + Minimal outliers

### When to Use It
We use the correlation hypothesis test when we want to determine whether the relationship between two non-outcome variables is significant or not.^[https://www.statology.org/when-to-use-correlation/] This makes it similarly useful in clinical trials, compared to linear regression analyses.
    
### Hypotheses
* The null and alternative hypotheses of this test are:
    + Ho: There isn't a significant linear relationship between the two variables in question
    + Ha: The relationship between these two variables is both linear and significant. There is an identifiable correlation between them
    
# The Primary Statistical Elements
Alongside statistical tests, there are two important elements present in virtually all quantitative analyses: the **hypotheses** and **p-value**. The former are developed towards the start of the experiment/study, and the latter is derived towards the end as part of the results. Without them, no one would be able to put forth meaningful information through such scientific endeavors. 

To this end, I will provide information on these elements. I hope to keep this so I can look back on it in the future.

## The Hypotheses
The hypotheses are composed of both the null and alternative hypotheses. These are devised in order to determine the potential outcomes of a given study/experiment/trial/etc. It's similar to a traditional scientific hypothesis, with the difference being that these outcomes are listed in the most statistically-technical manner possible, to prevent assumptions on the potential results. I've already described various hypotheses in the previous section, but I will go over each type in greater detail here.

### Null Hypothesis
The **null hypothesis** (commonly referred to as "h~o~" or "ho") will always state that there are no differences between sets of data, whether this is before and after a treatment, when comparing statistical values of different sets of data, etc. Even if differences are found, the h~o~ will write this off as a result of random error/variation in the data sets.

### Alternative Hypothesis
The **alternative hypothesis** (referred to as "h~a~" or "ha") will state the opposite of the former's proposition. This means that any differences found in data sets after performing the necessary tests are a result of direct, intentional intervention. In other words, if a clinical trial was being conducted, this hypothesis will state that the treatment being applied to the experimental group is directly affecting the results. 

### Making a Decision
When determining the final results of your experiment/study, you'll need to either **reject the h~o~ or accept it**. The former signifies that you've determined that a difference was made because of the applied treatment, while the latter means that you've determined that there was no actual difference in the populations.^[https://courses.lumenlearning.com/introstats1/chapter/null-and-alternative-hypotheses/]

## P-Values
While the null and alternative hypotheses are integral to setting up an experiment, **p-values** (a.k.a. probability values) are equally as such when closing one out. A p-value is the measure of confidence, or likelihood, of obtaining the same set of data when performing the experiment/study under the assumption of the h~o~.^[https://www.investopedia.com/terms/p/p-value.asp] In other words, a smaller p-value points more strongly to the h~a~. This makes obtaining as small of a p-value as possible desirable among researchers. 

While people generally try getting their p-values as small as possible (unless you've set out to disprove previous studies), a rule of thumb is that a p-value of 0.05 or less is considered sufficiently likely that the h~a~ is the true conclusion. This condition is known as **statistical significance**; If your experiment yields a p-value ≤ 0.05, it is considered statistically-significant. This is very good news if you're conducting a clinical trial! In this case, it would mean your treatment has a noticeable effect in the subjects, and can't reasonably be written off as random data variation.

# Visualizing Data
As demonstrated, there is a multitude of ways data can be manipulated to reach a desired result. However, it's almost just as important to be able to show yourself and others these data in an easier-to-digest form. No one wants to shovel through a sea of numbers to see what you're trying to prove. This is where **data visualization** comes in. Data visualization enables your peers to see the results of your efforts more easily. 

There are four primary methods of displaying such data, with each one depending on the nature of the data: **histograms, box plots, heat maps and pie charts**. I will be covering each one in the upcoming material.

## Histograms
### Overview
Histograms consist mainly of x and y-axes, combined with boxes of various lengths lined up horizontally; Legends and trend-lines usually compliment this as well. These are used to display how data is distributed.^[https://www.geeksforgeeks.org/maths/histogram/]. Due to the nature of histograms, they're commonly used to help visualize trends in a set of data across a continuous interval, or period. 

The difference between histograms and **bar charts** is a matter of the properties of the displayed data. While bar charts show categorical data with no need to display the period over which the data exists, histograms display how one set of data exists over a continuous interval, as stated before. The chunk of period a statistician will cut out for a histogram is called a **bin**.

Here is a link to an image of a typical histogram:
https://www.geeksforgeeks.org/maths/histogram/

### Terms to Know
* Statistical entities associated with histograms include:
    + **Central tendency**: Which value the majority of recorded samples fall into. This is represented as a peak in the histogram. There can be more than one peak, depending on data.^[https://statisticsbyjim.com/basics/histograms/]
    + **Symmetry**: The bars on a histogram chart can either be of the same frequency on both sides of the peak, or it can tend towards one side.
    + **Variability**: A measure of how much of a peak the chart displays. More variability yields a less-defined, more rounded-out peak. 
    
## Box Plots
### Overview
Box plots are very similar to histograms, except that multiple intervals can be displayed in one graph. This makes it useful for researchers, as it can display a lot of information in a single image.^[https://statisticsbyjim.com/graphs/box-plot/]. It's basically a simplified version of the data presented in multiple histograms. Box plots don't make assumptions on the distribution of the data, making it nonparametric. 

Here is a link to an image of a typical box plot: https://i0.wp.com/statisticsbyjim.com/wp-content/uploads/2019/01/boxplot_teaching.png?w=576&ssl=1

### Terms to Know
* Box plots outline their central tendencies and spreads through the **5-number summary**, which consist of:
    + **Minimum**: The smallest number in the interval's data set.
    + **First quartile**: The value that separates the bottom 25% of values from the rest of the data.
    + **Median**: The middle value of the data set. Can also be called the **second quartile**.
    + **Third quartile**: The value that separates the bottom 75% of values from the rest of the data.
    + **Maximum**: The largest number in the data set.
    
## Heat Maps
### Overview
Heat maps are typically used with large sets of data, all with values that can differ to various intensities.^[https://www.geeksforgeeks.org/data-visualization/what-is-heatmap-data-visualization-and-how-to-use-it/] This data visualization technique will chart the data in a color-coded fashion, according to a spectrum of values. Heat maps are typically displayed in a **2d or 3d** matrix, and use a range of values as a reference point for a color spectrum. 

For example, a heat map can graph the temperature distribution of a given area, with a spectrum ranging from red to blue; Redder colors are higher temperatures, while bluer colors are lower. The axes can represent the physical area the temperatures are being recorded over.

Here is an example of a typical 2-dimensional heat map... https://www.researchgate.net/publication/344202320/figure/fig5/AS:959980165414946@1605888515416/A-heat-map-of-the-two-dimensional-hierarchical-cluster-analysis-suggesting-differential.png

...As well as an example of a 3-dimensional one: https://drjohnsullivan.com/wp-content/uploads/2016/04/heat-map.jpg

### Terms to Know
* Some terms that are useful to know about when dealing with heat maps are:
    + **Matrix**: The area the axes give rise to. This can be either a 2 or 3-dimensional space where the values are plotted out. 
    + **Spectrum**: The range of values being depicted in the heat map's matrix, being displayed as a literal color spectrum. 
    + **Clustering**: The property of a heat map that helps group similar rows and columns together. Depicted as tree-like structures on the side of the matrix.
    
## Pie Charts
### Overview
Pie charts are likely one of the first data visualization methods one will use. This can be chalked up to their ease of use; However, they tend to be one of the most misused. ^[https://www.storytellingwithdata.com/blog/2020/5/14/what-is-a-pie-chart] A pie chart consists of a circle, with categorical data being represented on it as "slices." Larger slices mean it takes up a larger portion of a single population/variable.

These charts can come in a variety of shapes, such as rings and bars.

Here is an example of one: https://images.squarespace-cdn.com/content/v1/55b6a6dce4b089e11621d3ed/1589459527969-AMZ4OHKJ5ES2GLYKK9WV/2_sales+by+product.png?format=1000w

### Terms to Know
* Some terms to know when dealing with pie charts are:
    + **Slice**: The portion of a whole variable a singular piece of categorical data takes up, visually represented. Its size can also depict frequency something happens in one instance. 
    + **Pie**: The whole variable/population/instance. A typical pie represents **one** of these. Another type of chart would be needed if you were plotting categorical data across an interval. 
    
# Conclusion
There is a variety of ways in which a statistician can gather and process data to prove a point. Each test has a rich history of use, with their creators working tirelessly to finalize their methods. There are equally as many ways to visualize this data as there are methods to process it as well, each with unique conditions for use. I hope this article was illuminating for you; I will also be keeping this handy for future reference. 